(* ::Package:: *)

(* ::Section:: *)
(*1 Idea Summary*)


(* ::Text:: *)
(*This note is used to test schedule method for IoT crawler, which is used to sychronize the data from IoT sensor and a centralized repository. The mesurement of this test is the latency between the repository and the raw data. The main method of crawler scheduling is to distribute the crawl during a period of time as evenly as possible. The origin dataset of events of interests is generated in a Poisson Process, where the time interval between any two adjacent events follows the exponential distribution.*)
(**)
(*We first evaluate the fitting performance of a single sensor Subscript[E, f](t,Subscript[t, s]), which indicates the the expectation at time t of latency generated during time t and Subscript[t, s], in a simulation situation. This can be realized by sum the delay of events and compare them with Subscript[E, f](t,Subscript[t, s])*)
(**)
(*Then next step is check the performance of single sensor scheduling with the following situations: (a) non-hibernation, (b) period-hibernation, (c) hibernation but not periodic. For each situation, check the latency of sum of events with the optimal expectation generated by our optimal scheduling strategy.*)
(**)
(*At last, check the global scheduling method using iterative method. We start create test data by generating events from different sensors in a Poisson process manner for a time period [0,T) with different parameter \[Lambda]. Then we take these data as the input of the global refine algorithm. *)


(* ::Subsection:: *)
(*1.1 Expectation Function*)


(* ::Text:: *)
(*Before the analysis of expectation function, we define the follow parameters for convenience. \[Lambda] is the rate paramter for events generation, Subscript[T, 0] is an intact duty cycle, Subscript[T, w] is the working part and Subscript[T, h] is the hibernate part. In addition, we use Subscript[t, s] for the start of a time period, and t as a temp time variable.*)


(* ::Input:: *)
(*\[Lambda]=1/2;*)
(*Tw=5;*)
(*Th=10;*)


(* ::Text:: *)
(*We study the non-hibernation cases. The expectation function E[G(t)] can be computed using the follow equation:*)


(* ::Input:: *)
(*Clear[EG];*)
(*EG[t_,\[Lambda]_]:=(E^(-t \[Lambda])-1+t \[Lambda])t;*)
(*Plot[EG[t,1/2],{t,0,50}]*)


(* ::Text:: *)
(*Then we look into the hibernate case.*)


(* ::Input:: *)
(*Clear[EGH];*)
(*EGH[t_,\[Lambda]_,Th_,Tw_]:=Module[*)
(*{T0,K},*)
(*K=Floor[t/T0];*)
(*T0=Tw+Th;*)
(*If[Mod[t,T0]<= Tw,*)
(*EG[t-K T0,\[Lambda]]+*)
(*\!\( *)
(*\*SubsuperscriptBox[\(\[Sum]\), \(n = 1\), \(K\)]\((EG[t - \((K - n)\)\ T0, \[Lambda]] - EG[t - \((K - n)\) T0 - Tw, \[Lambda]])\)\),0]]*)
(*Plot[EGH[t,1/2,10,5],{t,0,50}]*)


(* ::Text:: *)
(*Finally, the expectation of a time period can be induced as follows:*)


(* ::Input:: *)
(*Clear[Ef];*)
(*Ef[t_,ts_,\[Lambda]_]:=EG[t-ts,\[Lambda]];*)
(*Plot3D[*)
(*Ef[t,ts,1/2],{t,0,100},*)
(*{ts,0,100}, *)
(*RegionFunction->Function[{x,y},x>=y],*)
(*PlotRange->All,AxesLabel->{t,Subscript[t, s]}]*)


(* ::Input:: *)
(*Clear[Efh];*)
(*Efh[t_,ts_,\[Lambda]_,Tw_,Th_]:=Module[*)
(*{T0},*)
(*T0=Tw+Th;*)
(*If[ts<=t && Mod[t,T0]<=Tw,*)
(*If[Tw<=Mod[ts,T0]<= T0,*)
(*EGH[t-ts-(T0-Mod[ts,T0]),\[Lambda],Tw,Th],*)
(*EGH[t-Floor[ts/T0]T0,\[Lambda],Tw,Th]-*)
(*(EG[t-Floor[ts/T0]T0,\[Lambda]]-EG[t-ts,\[Lambda]])],0]*)
(*];*)
(*Plot3D[Efh[t,ts,1/2,5,10],{t,0,100},{ts,0,100},*)
(*RegionFunction->Function[{x,y},x>=y],*)
(*PlotRange->All,*)
(*AxesLabel->{t,Subscript[t, s]}]*)


(* ::Subsection:: *)
(*1.2 Scheduling Method for Crawling of Single Sensors*)


(* ::Text:: *)
(*There are 3 different situations of crawling strategy for single sensors: non-hibernation, periodic, non-periodic. As inputs and outputs are the same, we will desgin process for each of the 3 problems.*)
(*Input: Time period [0,T), crawl times n*)
(*Output: sequence of time Subscript[t, 1],Subscript[t, 2],...,Subscript[t, n], optimal expectation value Eopt*)


(* ::Subsubsection:: *)
(*1.2.1 None Hibernation*)


(* ::Text:: *)
(*First for the non-hibernate situation, evenly crawl strategy is used for the sensors.*)


(* ::Input:: *)
(*Clear[OptNonHiber];*)
(*OptNonHiber[T_,\[Lambda]_,n_]:=Block[*)
(*{$R=<|opt->0,seq->{}|>,dt=T/n,t0=0,i=1},*)
(*While[i<=n,*)
(*AppendTo[$R[seq],t0+dt];*)
(*$R[opt]+=Ef[t0+dt,t0,\[Lambda]];*)
(*t0+=dt;i++];*)
(*$R];*)
(*ListPlot[Table[OptNonHiber[100,1/2,n,5,10][opt],{n,1,10,1}]]*)


(* ::Subsubsection:: *)
(*1.2.2 Non-Periodic Hibernation*)


(* ::Text:: *)
(*If there is no clear period of work cycle but the working schedule of sensor also is perviously known, then the schedule can be made in a dynamic programming approach. Here n is the crawl time and m is the number of all the possible working time. We setup a data set for test, for testing  the previous programs, using the follow command.*)


(* ::Input:: *)
(*Clear[CrawlUtility];*)
(*CrawlUtility[N_,w_]:=Module[*)
(*{$R=<|opt->\[Infinity],seq->{}|>,*)
(*M,f,p,n,m,k,minv=0,temp=0},*)
(*M=Dimensions[w][[1]];*)
(*f=Array[\[Infinity]&,{M,N}];*)
(*p=Array[0&,{M,N}];*)
(*For[m=1,m<=M,m++,*)
(*f[[m,1]]=w[[1,m]];p[[m,1]]=1];*)
(*For[n=2,n<=N,n++,*)
(*For[m=2,m<=M,m++,*)
(*For[k=2,k<=m-1,k++,*)
(*temp=f[[k,n-1]]+w[[k,m]];*)
(*If[temp<f[[m,n]],f[[m,n]]=temp;p[[m,n]]=k]*)
(*]]];*)
(*$R[opt]=f[[M,N]];*)
(*For[n=N;m=M,n>=0,n--,*)
(*AppendTo[$R[seq],m];m=p[[m,n]]];*)
(*$R];*)
(*w=RandomInteger[10,{5,5}];*)
(*w=ReplacePart[w,{i_,i_}->0];*)
(*CrawlUtility[3,w]*)


(* ::Subsection:: *)
(*1.3 Global Scheduling*)


(* ::Text:: *)
(*We use iterately improve the result, searching for best vector Subscript[n, i] of the crawl times for different sensors.  In each iteration, find the most profitable changes of Subscript[n, i].*)


(* ::Subsubsection:: *)
(*1.3.1 Data Initialization*)


(* ::Text:: *)
(*We first initialize a test case where there are 10 sensors, and randomly generate crawl times for each sensors along the timeline.  We generate different \[Lambda] for each sensor, called lambdaList, and setup a upper bound of total crawl number as \[Theta]. We use an iterater method for the final result, so we setup a bound \[Delta] to determine if the improvement made by the iteration is enough.*)


(* ::Input:: *)
(*sensors=10;*)
(*lambdaList=RandomReal[0.9,{sensors}]+0.1;*)
(*crawlLimitsList=RandomReal[15,{sensors}];*)
(*\[Theta]=RandomInteger[{25,30}];(*sum of crawl numbers*)*)
(*\[Delta]=0.1;*)
(*\[Epsilon]=2;*)
(*maxIteration=50;*)


(* ::Text:: *)
(*Then a time table is set for the schedule of hibernation. There are N elements in this time table, where each corresponse to a sensor. Each element a N*2 matrix, where first elements of each row are start time of a working cycle, and second elements are end time.*)


(* ::Input:: *)
(*TimeTable=Module[{*)
(*i,j,cycles,*)
(*maxwperiod=10,minwperiod=3,*)
(*maxwRange=10,minwRange=1,timeRange=200,*)
(*aList={},lList={},$tt={}},*)
(*For[i=0,i<sensors,i++;*)
(*cycles=RandomInteger[{minwperiod,maxwperiod}];*)
(*aList=Sort[RandomSample[Range[timeRange],cycles]];*)
(*lList=Array[0&,{cycles}];*)
(*For[j=0,j<cycles,j++;*)
(*If[j==cycles,*)
(*lList[[j]]=Max[RandomInteger[*)
(*Min[maxwRange,timeRange-aList[[j]]]],minwRange],*)
(*lList[[j]]=Max[RandomInteger[*)
(*Min[maxwRange,aList[[j+1]]-aList[[j]]]],minwRange]]];*)
(*AppendTo[$tt,Transpose[{aList,lList}]]];*)
(*$tt];*)


(* ::Subsubsection:: *)
(*1.3.2 Data Discretization*)


(* ::Text:: *)
(*We discretize the time table for conveniency. We evenly choose several points from the working cycles and compute the distance between each pair of time points, as an input for optimization. such discretization cause an analysable error bound. The discretization relay on the distance calculation between two different time node, which is also list as follows. Use the following command  to test the previous code.*)


(* ::Input:: *)
(*(*Distance*)*)
(*Clear[EG];*)
(*EG[t_,\[Lambda]_]:=(E^(-t \[Lambda])-1+t \[Lambda])t;*)
(*Clear[DistanceBetweenTimeNode];*)
(*DistanceBetweenTimeNode[timeLine_,\[Lambda]_,start_,end_]:=Module[*)
(*{$dd,cycles,pos},*)
(*cycles=Dimensions[timeLine][[1]];*)
(*pos=Position[timeLine,Select[timeLine,#[[1]]==start&]];*)
(*If[Length[pos]!=0,*)
(*$dd=EG[end-pos[[1]],\[Lambda]],*)
(*$dd=EG[end-start,\[Lambda]]];*)
(*$dd]*)
(*(*Discretization*)*)
(*Clear[DiscretizeTimeline];*)
(*DiscretizeTimeline[timeTable_,lambdaList_,stepLength_]:=Module[*)
(*{$dist={},candicateCnt,i,j,k,nodesCnt,*)
(*sensors,sensor,cycles,timeline,timeNode,workCycle,distanceMap},*)
(*sensors=Dimensions[timeTable][[1]];*)
(*For[sensor=0,sensor<sensors,sensor++;*)
(*timeNode={};*)
(*candicateCnt=0;*)
(*timeline=timeTable[[sensor]];*)
(*cycles=Dimensions[timeline][[1]];*)
(*For[i=0,i<cycles,i++;*)
(*workCycle=timeline[[i]];*)
(*timeNode=Join[timeNode,*)
(*Range[workCycle[[2]]+workCycle[[1]],workCycle[[1]],-stepLength]]];*)
(*timeNode=Sort[timeNode];*)
(*nodesCnt=Dimensions[timeNode][[1]];*)
(*distanceMap=Array[0&,{nodesCnt,nodesCnt}];*)
(*For[i=0,i<nodesCnt,i++;*)
(*For[j=i,j<nodesCnt,j++;*)
(*distanceMap[[i,j]]=DistanceBetweenTimeNode[*)
(*timeline,lambdaList[[sensor]],timeNode[[i]],timeNode[[j]]];];];*)
(*AppendTo[$dist,distanceMap]];*)
(*$dist]*)
(*$R=DiscretizeTimeline[TimeTable,lambdaList,\[Epsilon]]*)


(* ::Subsubsection:: *)
(*1.3.3 Pre-compute for Accelerate*)


(* ::Text:: *)
(*Here we pre-compute the cost of using certain times of crawls for different sensor.*)


(* ::Input:: *)
(*Clear[ExpectationForSensors];*)
(*ExpectationForSensors[dist_,maxCrawl_]:=Module[*)
(*{ret={},forone,crawl,sensor,ut},*)
(*For[sensor=0,sensor<Dimensions[dist][[1]],sensor++;*)
(*forone={};*)
(*For[crawl=0,crawl<maxCrawl,crawl++;*)
(*ut=CrawlUtility[crawl,dist[[sensor]]];*)
(*AppendTo[forone,ut[opt]];];*)
(*AppendTo[ret,forone]];*)
(*ret]*)
(*Clear[CrawlUtility];*)
(*CrawlUtility[N_,w_]:=Module[*)
(*{$R=<|opt->\[Infinity],seq->{}|>,*)
(*M,f,p,n,m,k,minv=0,temp=0},*)
(*M=Dimensions[w][[1]];*)
(*f=Array[\[Infinity]&,{M,N}];*)
(*p=Array[0&,{M,N}];*)
(*For[m=1,m<=M,m++,*)
(*f[[m,1]]=w[[1,m]];p[[m,1]]=1];*)
(*For[n=2,n<=N,n++,*)
(*For[m=2,m<=M,m++,*)
(*For[k=2,k<=m-1,k++,*)
(*temp=f[[k,n-1]]+w[[k,m]];*)
(*If[temp<f[[m,n]],f[[m,n]]=temp;p[[m,n]]=k]]]];*)
(*$R[opt]=f[[M,N]];*)
(*For[n=N;m=M,n>=1;m>=1,n--,*)
(*AppendTo[$R[seq],m];m=p[[m,n]]];*)
(*$R]*)
(*Expect=ExpectationForSensors[$R,\[Theta]]*)


(* ::Subsubsection:: *)
(*1.3.3 Iterative Method*)


(* ::Text:: *)
(*The final goal of the optimization is finding the minimum value. In each iteration, we use a greedy method to search for a best decrease for the target function with a fix step. This decrease must be caused by an increase of an arrangement and a decrease of another. The volume of the increase and decrease must match.*)


(* ::Input:: *)
(*(*Adjust the arrangment*)*)
(*Clear[ImproveSolution];*)
(*ImproveSolution[solv_,exptable_,crawlLimitsList_]:=Module[*)
(*{s1,s2,tmpArr,minExp,sensors,t,res},*)
(*minExp=\[Infinity];*)
(*res=Array[0&,{2}];*)
(*tmpArr=solv[arrange];*)
(*sensors=Dimensions[solv[arrange]][[1]];*)
(*For[s1=0,s1<sensors,s1++;*)
(*For[s2=0,s2<sensors,s2++;*)
(*If[s1!=s2&&tmpArr[[s1]]+1<=crawlLimitsList[[s1]]&&tmpArr[[s2]]>=1,*)
(*t=exptable[[s1,tmpArr[[s1]]+1]]-exptable[[s1,tmpArr[[s1]]]]*)
(*+exptable[[s2,tmpArr[[s2]]-1]]-exptable[[s2,tmpArr[[s2]]]];*)
(*If[t<minExp,minExp=t;res[[1]]=s1;res[[2]]=s2]*)
(*]];];*)
(*If[minExp<0,*)
(*tmpArr=solv[arrange];*)
(*tmpArr[[res[[1]]]]++;*)
(*tmpArr[[res[[2]]]]--;];*)
(*t=0;*)
(*For[s1=0,s1<sensors,s1++;*)
(*t+=exptable[[s1,tmpArr[[s1]]]];];*)
(*<|opt->t,arrange->tmpArr|>]*)


(* ::Subsubsection:: *)
(*1.3.4 Main Entry*)


(* ::Text:: *)
(*The global optimization method take the hibernation schedule of sensors and other parameters as input, and return the optimal crawl time for each sensor. (There's no need to return the specific schedule for each sensors, cause once the crawl times is chosen, the optimal schedule strategy for each sensor is fixed)*)


(* ::Input:: *)
(*(*Main entry*)*)
(*Clear[MainEntry];*)
(*MainEntry[lambdaList_,timeTable_,crawlLimitsList_,\[Theta]_,\[Delta]_,\[Epsilon]_,iteratorLimit_]:=Module[*)
(*{$R=<|opt->\[Infinity],arrange->{}|>,$oldR,sensors,t,i,dist={},expTable},*)
(*dist=DiscretizeTimeline[timeTable,lambdaList,\[Epsilon]];*)
(*expTable=ExpectationForSensors[dist,\[Theta]];*)
(*Print["Expectation computation done."];*)
(*$R[arrange]=EvenlyDivide[\[Theta],Dimensions[lambdaList][[1]]];*)
(*i=1;*)
(*While[Abs[$R[opt]-$oldR[opt]]>=\[Delta]&&i<iteratorLimit,*)
(*$oldR=$R;*)
(*$R=ImproveSolution[$R,expTable,crawlLimitsList];*)
(*Print["Iteration No."<>ToString[i]<>" opt is "<>ToString[$R[opt]]];i++;];*)
(*$R]*)
(*(*Utils function*)*)
(*Clear[EvenlyDivide];*)
(*EvenlyDivide[N_,L_]:=Module[*)
(*{$arr,t,i},*)
(*$arr=Array[Floor[N/L]&,{L}];*)
(*For[t=Mod[N,L];i=1,t>0,t--;$arr[[i]]++;i++];*)
(*$arr]*)
(*MainEntry[lambdaList,TimeTable,crawlLimitsList,\[Theta],\[Delta],\[Epsilon],maxIteration]*)


(* ::Section:: *)
(*2 Evaluation*)


(* ::Text:: *)
(*We use mathematica package file to store evaluation methods, and pick up some remarkable method for this notebook.*)


(* ::Subsection:: *)
(*2.1 Measurements and Methodology*)


(* ::Text:: *)
(*Several properties should be evaluated through the evaluation: The performance gain from the scheduling strategy, with different sensor scales, running time, and other initialization parameters.*)
(**)
(*We choose the object function, which is the overall latency expectation, as the basic benchmarker of our method. It's reasonable to choose a random select scheduling strategy and a evenly choose greedy method as competitors.*)
(**)
(*Performance as convergence rate (related to \[Epsilon]), approximation error imported through discretization and computation cost should also be evaluated.*)
(**)
(*We use the following codes to generate the TimeTable.*)


(* ::Input:: *)
(*Clear[TimeTableMaker];*)
(*TimeTableMaker[sensors_,maxwperiod_,minwperiod_,*)
(*maxwRange_,minwRange_,timeRange_]:=Module[{*)
(*i,j,cycles,aList={},lList={},$tt={}},*)
(*For[i=0,i<sensors,i++;*)
(*cycles=RandomInteger[{minwperiod,maxwperiod}];*)
(*aList=Sort[RandomSample[Range[timeRange],cycles]];*)
(*lList=Array[0&,{cycles}];*)
(*For[j=0,j<cycles,j++;*)
(*If[j==cycles,*)
(*lList[[j]]=Max[RandomInteger[*)
(*Min[maxwRange,timeRange-aList[[j]]]],minwRange],*)
(*lList[[j]]=Max[RandomInteger[*)
(*Min[maxwRange,aList[[j+1]]-aList[[j]]]],minwRange]]];*)
(*AppendTo[$tt,Transpose[{aList,lList}]]];*)
(*$tt]*)


(* ::Subsection:: *)
(*2.2 Global Scheduling Benchmark*)


(* ::Text:: *)
(*1. Sensor scale.*)
(*2. Crawl numbers.*)
(*3. Lambda,  generating rate of interesting informantion.*)
(*4. Gamma, energy limit of a single sensor.*)


(* ::Subsubsection:: *)
(*2.2.1 Sensor scale*)


(* ::Text:: *)
(*Random v.s. optimal*)


(* ::Subsection:: *)
(*2.3 Comparison*)


(* ::Text:: *)
(*Optimal schedule v.s. random schedule:*)
(**)
(*1. The overall computation cost.*)
(*2. Accruacy.*)
(**)
(*The boost with dynamic programming:*)
(**)
(*1. Random schedule.*)
(*2. Evenly schedule.*)
