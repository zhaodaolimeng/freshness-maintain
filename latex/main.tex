%% bare_conf.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

\documentclass[conference]{IEEEtran}

\usepackage{graphicx, url, tikz}
\usepackage{standalone}
\usepackage{amsmath,bm,times,amssymb}
\usepackage{mathtools}
\usepackage{algorithm,algorithmic}

\usetikzlibrary{datavisualization}
\usetikzlibrary{shapes,arrows,shadows}
\usetikzlibrary{datavisualization.formats.functions}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\RequirePackage[singlelinecheck=off]{caption}

%%%%
\definecolor{mygreen}{RGB}{117,167,117}
\definecolor{myred}{RGB}{255,1,1}
\newcommand\myent[1]{%
  \footnotesize%
  $#1$
}
%%%%

\newtheorem{condition}{Condition}
\newtheorem{assumption}{Assumption}
\newtheorem{colloary}{Colloary}
\newtheorem{theorem}{\bf Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{example}{Example}
\newtheorem{notation}{Notation}
\newtheorem{definition}{\bf Definition}
\newtheorem{remark}{Remark}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
% \title{Repository Freshness Maintain in a CoAP-based\\ IoT Search System}
% \title{Repository Freshness Maintain in a Web-based\\ IoT Search System}
% \title{EasiCS: An IoT Crawler Scheduling Method}
\title{EasiSC: A Sleep-aware Schedule Method for \\Recrawling IoT Devices}

% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{
\IEEEauthorblockN{Li Meng\IEEEauthorrefmark{1}\IEEEauthorrefmark{2}, Cui Li\IEEEauthorrefmark{1}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}Institute of Computing Technology, Chinese Academy of Sciences}
\IEEEauthorblockA{\IEEEauthorrefmark{2}Graduate University of the Chinese Academy of Sciences, China}
\IEEEauthorblockA{\{limeng, lcui\}@ict.ac.cn}
}

% make the title area
\maketitle


\begin{abstract}
%\boldmath
The search of IoT(Internet of things) is an important way for people to exploit useful devices. In this paper, we study the problem of crawling the content of low power IoT devices, which is a fundamental step towards building a generic IoT search engine.
The crawl of IoT devices is very different from that of Web. Many low-power devices may sleep periodically, causing invalid crawls and unreliably latency. Also, in IoT systems, energy consumption of crawl access becomes nonnegligible.
With these low-power devices widely used in IoT systems, traditional crawling schedule strategy is not suitable.
In this paper, a new scheduling method, EasiSC, is proposed to solve the scheduling problem of crawling periodically sleep IoT devices. The crawling problem with energy limits is formulated as a constraint optimization problem. We use the expectation of latency to measure the realtime performance of crawler scheduling. With this measurement as optimization goal, EasiSC can get the near optimal latency expectation, which is more device friendly and suitable for IoT search than traditional web search scheduling.
At last, EasiSC is evaluated with simulations. A case study is also performed with real world data from xively.com.
% At last, we use simulations to test the expectation of latency of our new scheduling method, which illustrates the effectiveness for repository freshness and lower energy impact on the IoT sensors.
\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}
% why IoT search is important
Searching of IoT(Internet of Things) is a basic step for users and applications to find different kinds of sensors and IoT devices. 
A generic IoT search engine can be used in variety scenes, which can improve the possibility of sharing sensors and device with others, which can significantly reduce the redundancy of sensor deploying. Also, different applications composition method like IFTTT\cite{ifttt} can be easily implied with the help of IoT search engine.
More specifically, in smart city applications, public sensors can be found in an ad hoc manner to provide predicates as traffic jam and queuing status. 
Smart home applications need searchable sensors and devices to detect human activities and provide human-centric sensing, which calls for a realtime sensor discovery mechanism. In recent future, unmanned systems like automatic driving systems and quad-copter delivery systems are likely to be heavily dependent on information gathered from nearby sensors or other IoT devices, which also needs IoT search. In these situations, an overall generic search engine is needed to collect the semantic descriptions of these sensors, and send response to users' queries. 


% why our problem is important
However, the design of IoT search engine is not a trivial problem, even with the help of standardized protocols and semantic descriptions of devices. The main problem lay in the internal instinct of IoT. Firstly, IoT devices is not connected by their content, which is precisely what user cares, link-based crawl method is infeasible for IoT search engine. Secondly, IoT devices, whose content can be highly dynamic, behaves differently from Web page, many of them may enter sleep mode periodically, meanwhile the realtime performance of search is a critical measurement. In this paper, we propose EasiSC, which is devoted to solve the sleep-aware IoT crawl problem.

% practicability
The built of generic IoT search engine is technically practical. Previous research use semantics\cite{Pfisterer2011} to enhance IoT device description methods. The conception ``description" as an abstraction of the state of a sensor.
Descriptions crawled by IoT search engines include not only static contents, but also dynamic contents which are generated by the sensor itself. Indeed, many research group are working on dynamic describing methods, such as CoRE\cite{CoREWorkingGroup2012} from IETF and SensorML\cite{botts2007opengis} from OGC. 
We are building an IoT search system, which means we treat sensors and devices as Web pages, whom can automatically update their description files that describe their realtime state.
We suppose every devices in this system supports IP protocol. These devices can generate description file automatically, which may content events detected by these sensors, the most recent updates of data, or simply static meta information about the sensors and their functions. 
IoT crawlers crawl different sensors and devices for these descriptions files, and copy these into a local copy at server end, called repository. The repository is an organized storage, with whom the user queries about IoT sensors can be accomplished.
The most obvious advantage of using this approach is that we don't need to invent wheels ourself. With maturity technology from information retrieval, there is no need to modify the server side architecture or protocols. There is even no need to modify the hardware of IoT sensors, if a sensor support protocols like CoAP.


However, IoT search is different from Web search, mainly because the search targets and higher real-time requirements. We also consider the possible energy constraints and sleep behavior of sensors, where over frequency device access may impact the battery life of IoT devices and result in invalid crawls. Information generated by sensors maybe out of date if the sensors are not crawled at a proper time. So, it's critical to choose crawling frequency and strategies for crawlers. 
In order to choose an appropriate strategy, we hold an assumption that the sensor message that user cares updated in a Poisson manner, and then design an update plan that maximum the expectation of the sum of the messages' freshness, which could be an important compromise between server storage and the aging of stream data generated by massive amount of sensors.

\begin{figure}
	\centering
	\includestandalone[width=\linewidth]{pic/fig1}
	\captionsetup{justification=centering}
	\caption{Framework of Pull-based IoT Search System}
	\label{fig:framework}
\end{figure}

Considering the stability and standardization advantages, in this paper the pull-based architecture is chose as the basic framework to study IoT crawl scheduling problem. The framework is illustrated by Fig.\ref{fig:framework}. 
We assume the user only interest in the events monitored by corresponded sensors, which arrives periodically or just randomly. With the help of semantic IoT method, IoT sensors capture the event stream, and continuously store these events, and update their description files correspondingly. In this manner, the description file reveal the realtime state of sensors. IoT search engine regularly access the IoT descriptions, then updates the related repository. CoAP with CoRE resource description method can be used as standardized protocol for sensors and devices, and the description messages are listed in the ./well-know file used in the CoRE framework. 


EasiSC is a scheduling strategy implemented at the server side as a role of IoT Crawl Scheduler. Our design principle is to minimize the information latency during  a period while meet the energy constraint of IoT devices, given sensor sleeping schedule and the frequency of event. Here we clarify that, if a device is sleeping, we indicate that all its communication and event detection function are disabled.
The insight of the solution lies in the convexity of the function between crawl times and latency for a single device. If convexity of the object function holds, the minimization problem can be solved by the follow two sub problems: (1) How to decrease the object function by rearranging crawl times for each sensors during a fix length of time? (2) What's the best scheduling strategy for each sensor? Luckily, the convexity can proof with some constraints. EasiSC is implemented in a iterative way based on these analyze. For each steps, EasiSC compute the minimum sum of latency that can achieved by the current crawler arrangement, and then rearrange to see if the result can be improved.
Our paper is organized as follows. We formalize the optimization problem in section II, then introduce EasiSC in section III. Simulations and a case study are preformed in section IV. 

This paper has three contributions.
(1) Although crawler scheduling problem is well studied in the field of IR, to our best knowledge, our paper is the first to consider the crawling problem in IoT system and formalize it as an constraint optimization problem.
(2) A practical heuristic approach EasiSC for crawler scheduling under different circumstances is proposed for this model, which is evaluated in simulation.
(3) We studied the real world data crawled from the IoT platform xively.com, which indicates the feasibility of our methods.

\section{Related Work}

Crawlers Scheduling is a well studied topic in the field of Web search. Previous works\cite{Cho2000}\cite{Wolf2002}\cite{Challenger2004} analyzed how the crawler strategy affect the freshness of the repository of web pages maintained by web crawlers, which determines the query hit rate and whether this system can return a up-to-date result. However, In a IoT search system, the realtime requirements can be more strict while some inherent properties of IoT like the sleep of IoT devices and resource constraints, make IoT crawler's strategy very different from crawlers in a traditional Web search engine. 


The schedule strategy has intimate connections with IoT search architectures.
Many different architectures of IoT search have been proposed, which can mainly be divided into two different architectures, push-based or pull-based.
In a push-based system, the realtime performance is a prior. Sensor data are periodically sent and stored in servers, and search request are actually running on continuous datastreams. Many practical applications collect data from sensors, and perform query directly in databases using SQL. Technologies like TinyDB\cite{TinyDB} and IoT feeds\cite{Whitehouse2006} take IoT devices as datasources, and process structured command to query the data stream generated by these devices. This kind of IoT architecture are easy to implement, but can be clumsy sometime. In many applications, not all data is need to be sent and uploaded to server, and this problem seems inevitable because it's almost impossible for sensors and devices to know exactly what the user want.
On the other side may be the solution to the requirement match problem.
Pull-based architecture use semantic description, i.e. XML, to describe IoT sensors and devices. Devices update their description based on data collected, which make the behavior of whom very similar to a web page. This property makes search IoT with a traditional Web search engine possible. For example, Dyser\cite{Dyser} use crawlers and modern indexing methods, along with semantic IoT technology as IoT device descriptions. Previous works of semantic IoT\cite{Compton2012} and the propose of CoRE\cite{CoREWorkingGroup2012} devoted to standardize IoT device description languages, which indicated the possibility of building a web-style IoT search system. Although the communication over-head of pull-based architecture is relatively heavy, and when lacking of prior information, most crawlers schedule methods are actually myopic, the scalability make pull-based IoT search architecture very promising.


We also look into technologies used in LAN to automate home devices, which may also be used in IoT applications. For example, UPnP\cite{UPnP}, Bonjour\cite{Bonjour} and other prevalent network configure protocols. But they are not perfectly suitable for IoT applications, mainly because the device description language can not define the realtime state of IoT devices. Also, most of this configure protocol can only be used in LAN environment, with limit amount of devices.

\section{Preliminaries and Measurements}
EasiSC are implemented on a pull-based IoT search architecture, where any events captured by IoT devices are stored in their semantic descriptions. Crawlers periodically visit a device to copied the description to the server.
In addition, we setup the follow assumptions to simplify the device model. 
(1) Events that users care arrived at each IoT device in a Poisson manner, where the time interval between any two event follows exponential distribution. 
(2) In the sleep mode, devices can be accessed by crawlers, no new events can be captured, which means accessing a sleeping device can only get the event captured by the last working duty cycle. This assumption is actually reasonable for some fifo enabled devices like webcams. 
(3) User only cares about the event latency, which is the object function for optimization.


EasiSC is periodically scheduled with the same strategy, so only time period $[0, T]$ is discussed in the following paper.
Suppose there are totally $N$ devices needs to be re-crawled, while crawler can perform at most $M$ times of crawls during the period $[0, T]$. Our goal is to find a schedule strategy $\phi$, so the latency of all $N$ IoT devices is minimized.


The latency talked in this paper is defined as the expectation of the duration from when the events are captured by devices to the time when crawler copy these events to the server side repository. In other words, the latency is opposite to the freshness of all the events user get from the repository.
In this paper, we mainly study the measurements of latency expectation when the sleep pattern is previously known.
To measure the latency expectation at a certain time $t$, we define $E_f(t, t_s)$ as the expectation when crawler crawls the IoT device at time $t$, and $t_s$ is the last time this device is crawled. In addition, we use the annotation $G(t)$ as latency expectation for crawling at time $t$.

This is a well-studied problem which has been studied by \cite{Cho2000, Wolf2002}. Our key idea is to check the expectations when different number of events happened, and add these expectations up. Details are presented in the appendices. 






\section{EasiSC: A Scheduling Strategy for\\IoT Crawlers}

We first give out our method to iteratively improve our solution, in order to achieve the optimal scheduling strategy, then introduce technical details of these subroutines, including the schedule method for periodic or unperiodic sleep devices. At last, we discuss the strategy for devices whose sleep plan is previously unknown.
\subsection{Global Solutions}

Suppose the crawlers commit $n$ crawling actions during time period $[0, T]$. With strategy $\phi$, for each time the repository latency is $E(\phi)$, where $i=1,\ldots,n$. 
$\phi$ is an access sequence for different devices, where each $\phi_{i,j}\in{0,1}$. If sensor $i$ is planned to be crawled at time $j$, then $\phi_{i,j}=1$, where time $j$ belongs to a discrete time table $\mathbf{T}$, which is all the possible time that strategy $\phi$ can be implied at.
The access count of all the sensors during $[0, T]$ can be defined as $\Arrowvert\phi\mathbf{T} \Arrowvert_{1}$. We can define the count of sensor $S_k$'s access time $\sum_{i=1}^{N}\phi_{i,k}$, just in the same way as the total time. 
Considering the difference between sensors, we define $\omega_i$ as the expectation weight of sensor $i$. Then the final object function can be evaluated as $\Arrowvert \omega_i E(\phi) \Arrowvert_{1}$.


In addition, this problem must follow several constraints. Server load and IoT devices' energy consumption are two main limitations to consider as discussed above. 
The energy constraint of the sensor can be formalized directly: any IoT devices cannot be accessed too frequently, which means any period $[0, T]$, the access time $C_i$ for sensor $i$ is limited to be accessed less than $\gamma_i$ times. For the server load, our settings are similar to the formal research\cite{Wolf2002}, where the crawlers from the server can not commit more that $\theta$ crawls during time period$[0, T]$.
With the object function and constraints, we get the following optimization problem:
\begin{eqnarray}
\begin{array}{ll}
\min_{\phi}&\Arrowvert \omega_i E(\phi) \Arrowvert_{1}\\
\text{s.t.}
&\Arrowvert \phi \Arrowvert_{1}\leq\theta\\
&\sum_{\forall t \in \mathbf{T}}{\phi_{i,t}}\leq\gamma_i\\
&i=1,\ldots,N
\end{array}\label{OBJ}
\end{eqnarray}

Problem \eqref{OBJ} is a generalized formulation, which does not content specific event model and sleep behavior of IoT devices. In the follow section, we will start from a simplest periodic event capture model and look into the complete form of \eqref{OBJ}.

% With the relationship between number of crawls and expectation latency, we can get the optimal strategy for all sensors
In previous section, we figure out the relationship between the number of crawls and the expectation of latency $E_L(n)$. 
Now the object function of formulation \ref{OBJ} can be rewrite as $\sum_{i=1}^{N} \omega_i E_L(n_i)$. The bandwidth constraint can be taken as $\sum_{i=1}^{N} n_i < M$ and the energy constraint of single sensor can be rewrite as $n_i<\gamma_i$.


Once crawl times $n$ is chosen, then the optimal crawl strategy for a single sensor is determined, and every function of $E_L(n)$ is non-decreasing,  we design a naive approach which is very similar to SMO\cite{Platt1998}. 
The big figure is to dispatch crawl time and continuously refine the dispatch strategy until no improvement can be made.
First we dispatch the $M$ crawl time to $N$ sensors according to $\omega_i$. Then we start to search sensors for a pair $i$, $j$. If $i\gets i-1$ and $j\gets j+1$ will cause a largest improvement to the object function compared to the other pairs, then changes of $i$ and $j$ are conformed. Continue this process until none improvement can be made.


\subsection{Periodic Sleep Devices}

Next, we introduce the crawling strategy for single device, in variety situations, which is the subroutine of ??????the global algorithm.%%%%%%.
Due to different requirements between IoT applications, it's not rational to use an universal model to formalize the sleep pattern. For many devices, the sleep pattern is unknown, while others may have an per-arranged. 
We first focused on the scheduling of arranged sleep pattern, which are more likely to bring potential freshness gain through fixed amount of crawl actions.

In the situation when IoT devices continuously work, an intuition is to evenly distributed the crawling action across the crawling schedule. Here a proof of this proposition is given.

\begin{lemma}
\label{evenly}
In a continuous situation where no sensor hibernates, the optimal strategy is to scatter the crawl action over the timeline $t\in [0, T]$ as evenly as possible, where $T$ is a constant.
\end{lemma}

\begin{proof}
The evenly crawl proposition here can be proved by the convexity of $E_h[G(t)]$ \cite{boyd2004convex}. Here we donate $E_h[G(t)]$ as $f(t)$ for convenience. 
We start the proof with a simple situation where only two crawling are allowed. 
As a result, the whole expectation gain during $[0,T]$, which is marked as $F(0, T)$, is divided into two part, $f(t)$ and $f(T-t)$. With the convexity of $f(t)$, we get $2f(T/2)<f(T/2-\epsilon)+f(T/2+\epsilon)$ for $\forall{\epsilon>0}$. By substituting $F(T)=f(t)+f(T-t)$ into it, we get $F(T/2)<F(T/2+\epsilon)$ for $\forall{\epsilon>0}$, indicating $T/2$ is the minimum point of $F(t)$.


This conclusion can be generalized to a normal situation where multiply crawling are committed with the following induction. 
Now suppose there are $n$ crawling action, among which first $n-1$ action evenly divide the timeline. The time length of $n$-th crawling action does not equal to the adjacent one's, and we claimed this strategy is optimal. For any adjacent pair divided by a single crawling action, if the division is not evenly, we can choose the evenly one as a new strategy, which can lead to a larger $F(t)$ according to the proposition above, which is a contradiction.
\end{proof}


With \ref{evenly}, we can get the exact increment of expectation when different crawling times are implied to a same sensor. This can be used to minimize the overall expectation of repository latency, which formalized as $\Arrowvert \phi\mathbf{T} \Arrowvert_{1}$ above.
Here the relationship between crawling time and $E[\phi(n)]$ can be computed simply as follows, where $\phi(n)$ stands for the optimal strategy with $n$ crawls, and $T$ is the time period within consideration. 
\begin{equation}
E[\phi(n)]=nE[G(\frac{T}{n})]\label{NonHib}
\end{equation}
Function \eqref{NonHib} can be rewrite to an close-form expression as $T(T\lambda/n-1+e^{-T\lambda/n})$, which is convex. with this function, the minimum expectation can be calculated directly.

\subsection{Non-periodic Sleep Devices}
Here we also study the relationship between $n$ and the minimum latency expectation, but try to be more pragmatic.
With the optimal strategy $\phi_i(n)$ for sensor $i$ which is only related to the crawling time $n$, we can substitute functions \eqref{Eftts} and \eqref{EGHSimple} into \eqref{OBJ} to get the latency expectation of non-hibernation version. 
But with hibernation, at some time points the sensors can not be accessed, resulting in a complex piecewise expectation function, which makes the relationship between $n$ and $\phi_i(n)$ unclear and completely theoretical approach likely impossible.
Here we focus on the situation when $T_w<T_h$ and $n<T/\Delta T$. Applications which hold $T_w\leq T_h$ is rare, while if $n<T/\Delta T$ is just the same as the push situation we talked before.
A concrete formulation extends from \ref{OBJ} is as follows, where $\mathbf{t}$ is the set of target time sequence that a crawl action can be scheduled to, and $k\leq 0$.

\begin{eqnarray}
\begin{array}{ll}
\min_{\mathbf{t}}& E_f(T,t_n)+\sum_{i=1}^{n-1}E_f(t_{i+1},t_{i}) \\
\text{s.t.} 
&t_1,t_2,\ldots,t_n\in \mathbf{t}, n>0\\
&0<t_1<t_2<\ldots<t_n<T\\
&t_i\in[t_s+k \Delta T, t_s+T_w+k\Delta T]\text{, }t_i\in{\mathbf{t}}
\end{array}\label{OBJext}
\end{eqnarray}

We first look into sub-problems in privilege to design algorithm for problem \ref{OBJext}.
Here an intuition of the problem is to arrange the crawls at the end of a work cycle, we show this intuition is indeed an optimal strategy when the crawl interval is an integral multiple of duty cycle $\Delta T$. We uses the same symbols as the previous.

\begin{lemma}
\label{intopt}
If the time interval of an adjacent pair of crawls at $t$ and $t+\Delta t$ is an integral multiple of duty cycle, then the optimal crawl time $t$ follows $t\bmod \Delta T=T_w$.
\end{lemma}

\begin{proof}
The difference between expectations with two different time intervals, which have the different offset and have the same length multiple of duty cycle, can be written as $E_f(t, t_s)-E_f(t+\Delta t, t_s+\Delta t)$. 
The expansion of $E_f(t,t_s)$ is $E_h[G(t'')]-E[G(t)'']+E[G(t-t_s)]$, notice that $E_h[G(t'')]$ has a lower change rate compared with $E[G(t)]$, whose coefficient is $T_w/\Delta T$ instead of $1$. This indicates that the previous difference is a non-increasing function, which the optimal is the minimum when $\Delta t =T_w$.
\end{proof}


% How about the general situation? The same
The solution of the general situation is very similar to the previous when both $t$ and $t+\Delta t$ locate in working cycles. However, when crawl $t+\Delta t$  locate in a hibernate cycle the expectation will become $0$. Also, the result will become opposite when $t$ locate in a hibernate cycle while $t+\Delta t$ locate in a working one. In this situation, the expectation will become larger with more time of work cycle included into the expectation area. 
With these observations, we can design a strategy that in some circumstances, the optimal solution can be retrieved.

\begin{algorithm}
\caption{Heuristic Method of Latency Minimum Periodic Crawl}
  \begin{algorithmic}[1]
  \renewcommand{\algorithmicrequire}{\textbf{Input:}}
  \renewcommand{\algorithmicensure}{\textbf{Output:}}
  \REQUIRE $n$, $T$, $T_w$, $T_h$
  \ENSURE  $t_1,\ldots,t_n$
  \\ 
  \STATE $m \gets T/(\Delta T n)$, $r\gets (T/\Delta T)\bmod{n}$
  \FOR{$i=1$ to $m$}
    \STATE $t_{m-i+1}\gets T-\Delta T i + T_w$
    \IF{$i\ne 0 \land r\ne 0$}
    	\STATE $t_{m-i-1}\gets t_{m-i+1}-\Delta T$
        \STATE $r\gets r-1$
    \ENDIF
  \ENDFOR
  \RETURN $t_1,\ldots,t_n$
  \end{algorithmic} 
\end{algorithm}

The result can be computed in one pass, so the complexity of this approach is $O(n)$, where $n$ is the size of crawl times.

%%\subsection{Non-periodic Hibernate Sensors}
% When the working time can be seen as a point in timeline, original problem can be transform to a selection problem.
% The transform should be defined.
Our hibernation model is periodic and predictable in the previous example. However, in a real world IoT system, duty cycle in a hibernation mechanism is very likely to be non-periodic, and hibernation time will be the major action of the sensor, where $T_h\gg T_w$ holds. Also the crawling interval maybe much larger than $T_h$. 
If the length of working cycles are neglected and represented as time points, then problem of searching optimal crawling can be transformed to a search problem, which can be solved by dynamic programming.


Here a directed acyclic graph(DAG) model $G(E,V)$ is used to formalize the non-periodic hibernate problem.
$E$ are the edges of the graph, and $V$ are the vertex. We suppose there are $m$ vertex. 
If there are $T'$ time points in the timeline which stand for the non-periodic working cycle. Corresponding, there are exactly $T'$ vertex in this graph, from number $1$ to number $T$. 
We define $n$ as the count of crawls used, which indicates there are $n-1$ vertex allowed to pass, because the last vertex must be chosen. 
Now we take every points which stand for the working cycle as graph vertex, written as $v_i$. We defined that, for each pair of time points $t_i$ and $t_j$, if $t_i<t_j$, a directed edge $e_{i,j}$ from $v_i$ to $v_j$ is added to the graph, where $t_i$ and $t_j$ are all . A weight value $w_{ij}$ is set to $e_{i,j}$, whose value is $E_f(t_j, t_i)$, the expectation gain of a crawl at time $t_j$ whose previous crawl is at $t_i$.
Our problem is, how to find a path $e_{1,i},\ldots,e_{j,T}$ from $v_1$ to $v_m$, which take exactly $n$ steps, that minimum the sum of all the weights along. This transform process can be illustrated by Fig. \ref{fig:problemtrans}.

\begin{figure}
\centering
\includestandalone[width=\linewidth]{pic/fig3}
\captionsetup{justification=centering}
\caption{Example of Non-periodic Hibernate Problem Transformation}
\label{fig:problemtrans}
\end{figure}


With an acceptable scale of time range $T$ and crawl time $n$, this problem can be solved by dynamic programming. The solution state with a vertex $v_i$ and the available crawl time $n'$ left can be used as an sub-problem. Noticing the optimal expectation can be computed by adding weight $w_{i,j}$ with all the expectation known in sub-problems. The recursive relationship is summarized as follows:

\[f(v_i, n')=\left\{
    \begin{array}{lr}
	\min_{k=1}^{i-1}\{f(v_{i-k}, n'-1)+w_{i,i-k}\}\\
    \text{if }i\in[1, m-1]\\
    0\text{ if }n'=0\text{ and }i=1\\
    \infty\text{ otherwise}
    \end{array}\numberthis \label{dp}
    \right.
\]


$f(v_i,n')$ is the sum of weight of a path that start from $v_1$ and end with $v_i$, with cost exactly $n$ steps. In each step, we go over the  The computation complexity of iterating process is $O(T^2n)$, in which $nT$ sub-problem are computed and each computation will cost $n$ operations. The backtrack method uses $p(v_i, n)$ to get the optimal strategy, which takes at most $n$ steps. As a result, the overall complexity is still $O(T^2n)$ 

\begin{algorithm}
\caption{Latency Minimum Non-periodic Crawl Method}
  \label{alg:dp_min}
  \begin{algorithmic}[1]
  \renewcommand{\algorithmicrequire}{\textbf{Input:}}
  \renewcommand{\algorithmicensure}{\textbf{Output:}}
  \REQUIRE $G(V,E)$, $n$
  \ENSURE  $t_1,\ldots,t_n$
  \\
  \STATE $f(v_i,n') \gets \infty$, $p(v_i,n')\gets 0$
  \FOR{$n'=1$ to $n-1$}
  	\FOR{$i=2$ to $m$}
      \STATE $f(v_i,n')\gets\min_{k=1}^{i-1}\{f(v_{i-k}, n'-1)+w_{i,i-k}\}$
      \STATE $p(v_i,n')\gets$ minimum $v_{i-k}$
    \ENDFOR
  \ENDFOR
  \STATE $t_n\gets T$, $t_i\gets$back trace from $p(v_i, n)$ for $t_i$
  \RETURN $t_1,\ldots,t_n$
  \end{algorithmic}
\end{algorithm}

\subsection{If Sleep Pattern is Unknown}
To our best knowledge, for the unknown sleep pattern case, if there are latent pattern for the sleep behavior, the detection and scheduling can be formed as an multi-armed bandit problem, which is know NP-hard. If there are no latent pattern for sleep behavior, then there will be not optimal strategy expect for periodically device querying, which is definitely an inefficiency schedule method. 


\section{Simulation and Evaluation}


\subsection{Measurement}

\subsection{Parameters}

\subsection{Compare with Random Scheduling}


\section{Conclusion}


\section*{Acknowledgment}


The authors would like to thank...


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi


\bibliographystyle{unsrt}%{IEEEtran}%{unsrt}
\bibliography{reference}


%
%
%
%

\appendices
\section{Analysis of Latency Expectation}

\subsection{Without Sleep Mode}
Although previous work\cite{Cho2000} give out a similar result, we introduce a simpler way for deducing $E_f(t_s, t)$ when device works without sleep. For simplification, suppose the IoT device crawled start working at time $0$. The total freshness latency when crawl at time $t$ can be considered as an random variable $G(t)$, so our goal can be rewritten to compute the expectation $G(t)$, written as $E[G(t)]$. 
Notice $E[G(t)]$ can be divide into different parts due to the count of events $U_i$ happen during $[0, t)$, then $E[G(t)]$ can be written as:
\begin{equation}
E[G(t)] = \sum_{n=1}^{\infty} E[G(t)|N(t)=n]P(N(t)=n) \label{EG}
\end{equation}

$P(N(t)=n)$ is the probability of having $n$ events during $[0,t)$, which follows Poisson Distribution, holding $P(N(t)=n)=e^{-\lambda t}{(\lambda t)^n}/{n!}$ . $E[G(t)|N(t)=n]$ can be resolved as $\frac{n}{\lambda}(t\lambda+e^{-\lambda t_m}-1)$. $t_{m}$ stands for the happened time of the $m$-th event. Taking \eqref{EG} , we get the close form solution of the expectation as equation \eqref{ExpectCont}.
\begin{equation}
E[G(t)] = (e^{-t\lambda}-1+t \lambda)t \numberthis \label{ExpectCont}
\end{equation}

\subsection{Latency Expectation With Sleep Mode}
For the sleep situation, device starts to work at time $t_s$, and begin to work with a sleep plan.
Here we mark $T^{c}_{i}$ as the $i$-th working cycle. $\Delta T^{c}_{i} = T^{w}_{i}+T^{s}_{i}$, where $T^{w}_{i}$ is the $i$-th time periods when a device is awake and $T^{w}$ is the $i$-th sleeping cycle. 
It's hard to directly deduce an expectation for a Poisson process whose timeline is break up. However, with equation \eqref{ExpectCont}, we can compute the $E_f(t, t_s)$ by subtract the expectation cause by the previous crawls from $E[G(t)]$. In this recursive way, the expectation can be calculated. Here $E_s[G(t)]$ stands for the expectation to crawl a sleep enabled device at time $t$, $E[G(t)]$ still stands for the expectation if this particular device doesn't sleep.
Suppose start time $t_s=0$, $E_f(t_s,t)$ can be written as $E_s[G(t)]$, with the method above, the problem can be induced as the following if time $t$ is in an working period, which is written as $t \in [t_s + \sum_{i=1}^{k} T^{c}_{i}, t_s + \sum_{i=1}^{k} T^{c}_{i} + T^{w}_{i})$, where $k\in\mathbb{N}$.
\begin{align*}
E_h[G(t)] & = E[G(t-T^{L}(K))] + \\
	& \sum_{i=1}^{K}(E[G(t-T^{L}(K-i))]-\\
	& E[G(t-T^{L}(K-i)-T_w)]) \numberthis \label{ExpectSleep}
\end{align*}

%\begin{align*}
%E_h[G(t)] & = E[G(t-K T^{c})] + \\
%& \sum_{i=1}^{K}(E[G(t-(K-i)\Delta T)]-\\
%& E[G(t-(K-i)\Delta T-T_w)]) \numberthis \label{ExpectSleep}
%\end{align*}
Here $T^{L}(K) = \sum_{j=1}^{K} T^{c}_{j}$, which is time duration of first $K$ cycles, where $K$ is the count of integrated cycle $T^{C}$. Notice that for any other $t$, $E_h[G(t)]=0$, because crawlers are not allowed to access a hibernating sensor. For any time $t$ in a sensor working cycle, by summing those expectations caused by working cycle before $t$, we can get the overall expectation of out-of-time level when considering sensor's hibernation. 

\subsection{Crawls in an Arbitrary Period}

At last, we consider the original problem of computing $E_f(t,t_s)$ if $t\ne0$. This problem be divided into two situation according to the value of $t_s$, if $t_s$ is at a working cycle, the expectation can be estimate by $E_h[G(t)]$ which start at $0$ and subtract the expectation latency cause by the events arriving at time $[0, t_s)$, which is $E_f(t,t_s)=E_h[G(t'')]-(E[G(t'')]-E[G(t-t_s)])]$. 

We define $t'=t_s-t_s\bmod\Delta T$ and $t''=t-\floor{t_s/\Delta T}\Delta T$ for convenience. Here the minuend means the expectation at time point $t$ of latency during time period $[0, t_s]$.
If $t_s$ is at a hibernate cycle, then the result expectation is just as the one which $t_s$ equals next duty cycle, which is $E_h[G(t')]$, which can be written as follows.
\[E_f(t,t_s)=\left\{
    \begin{array}{lr}
    E_h[G(t')]\text{ if } t_s\bmod\Delta T\in [T_w, \Delta T)\\
    E_h[G(t'')]-E[G(t'')]+E[G(t-t_s)]\\
    \text{ otherwise }
    \end{array}\numberthis \label{Eftts}
    \right.
\]


Combine expression \eqref{EGH} and \eqref{Eftts}, the expectation of freshness latency is defined in the problem of hibernate involved crawling.

\end{document}